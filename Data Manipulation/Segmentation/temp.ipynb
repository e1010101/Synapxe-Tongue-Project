{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "from datasets import Dataset, DatasetDict, Features, Image, Sequence, Value, concatenate_datasets\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import PIL\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HF_KEY = os.getenv(\"ENVIRONMENT_VARIABLE_NAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bda1d06f014e8dbe9f82a3939b4208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"train_labels.csv\")\n",
    "valid_df = pd.read_csv(\"valid_labels.csv\")\n",
    "test_df = pd.read_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['Crack', 'Red-Dots', 'Toothmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary-encoded features to array of labels\n",
    "def binary_to_labels(row, label_cols):\n",
    "    return [float(row[col]) for col in label_cols]\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['labels'] = df.apply(lambda row: binary_to_labels(row, label_columns), axis=1)\n",
    "    df.drop(columns=label_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append image path to filename\n",
    "def add_image_path(df, split):\n",
    "    df['image'] = data_path + split + \"_segmented/\" + df['filename']\n",
    "    # Check if file exists and remove row if it doesn't\n",
    "    df = df[df['image'].apply(os.path.exists)]\n",
    "    return df[['image', 'labels']]\n",
    "\n",
    "train_dataset_df = add_image_path(train_df, \"train\")\n",
    "valid_dataset_df = add_image_path(valid_df, \"valid\")\n",
    "test_dataset_df = add_image_path(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>output/train_segmented/segmented_0.png</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>output/train_segmented/segmented_1.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>output/train_segmented/segmented_2.png</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>output/train_segmented/segmented_3.png</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>output/train_segmented/segmented_4.png</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739</th>\n",
       "      <td>output/train_segmented/segmented_739.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>output/train_segmented/segmented_740.png</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>output/train_segmented/segmented_741.png</td>\n",
       "      <td>[1.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>output/train_segmented/segmented_742.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>output/train_segmented/segmented_744.png</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        image           labels\n",
       "0      output/train_segmented/segmented_0.png  [0.0, 0.0, 1.0]\n",
       "1      output/train_segmented/segmented_1.png  [1.0, 1.0, 1.0]\n",
       "2      output/train_segmented/segmented_2.png  [0.0, 1.0, 0.0]\n",
       "3      output/train_segmented/segmented_3.png  [0.0, 1.0, 0.0]\n",
       "4      output/train_segmented/segmented_4.png  [0.0, 1.0, 1.0]\n",
       "..                                        ...              ...\n",
       "739  output/train_segmented/segmented_739.png  [1.0, 1.0, 1.0]\n",
       "740  output/train_segmented/segmented_740.png  [1.0, 1.0, 0.0]\n",
       "741  output/train_segmented/segmented_741.png  [1.0, 0.0, 1.0]\n",
       "742  output/train_segmented/segmented_742.png  [1.0, 1.0, 1.0]\n",
       "744  output/train_segmented/segmented_744.png  [0.0, 1.0, 1.0]\n",
       "\n",
       "[619 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "class_names = ['Crack', 'Red-Dots', 'Toothmark']\n",
    "\n",
    "# Labels is an array of floats\n",
    "features = Features({\n",
    "    'image': Image(),\n",
    "    'labels': Sequence(feature=Value('float32'), length=num_classes)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels example: image     output/train_segmented/segmented_0.png\n",
      "labels                           [0.0, 0.0, 1.0]\n",
      "Name: 0, dtype: object\n",
      "Validation labels example: image     output/valid_segmented/segmented_0.png\n",
      "labels                           [1.0, 1.0, 1.0]\n",
      "Name: 0, dtype: object\n",
      "Test labels example: image     output/test_segmented/segmented_0.png\n",
      "labels                          [0.0, 1.0, 0.0]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train labels example:\", train_dataset_df.iloc[0])\n",
    "print(\"Validation labels example:\", valid_dataset_df.iloc[0])\n",
    "print(\"Test labels example:\", test_dataset_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset_df, features=features, preserve_index=False)\n",
    "valid_dataset = Dataset.from_pandas(valid_dataset_df, features=features, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_dataset_df, features=features, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "619\n",
      "181\n",
      "94\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "# Modify depending on model\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = A.Compose([\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(),\n",
    "    A.GaussianBlur(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.HueSaturationValue(p=0.5),\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_test_transforms = A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(example):\n",
    "    image = np.array(example['image'])\n",
    "    augmented = train_transforms(image=image)['image']\n",
    "    return {\n",
    "        'image': PIL.Image.fromarray(augmented.permute(1, 2, 0).byte().numpy()),\n",
    "        'labels': example['labels']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cad23e62be34ec6a397ec9c9ae580c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/619 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "augmented_train_dataset = train_dataset.map(augment_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_train_dataset = concatenate_datasets([train_dataset, augmented_train_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    images = image_processor(examples['image'], return_tensors='pt')\n",
    "    labels = torch.tensor(examples['labels'], dtype=torch.float)\n",
    "    \n",
    "    return {\n",
    "        'image': examples['image'],\n",
    "        'pixel_values': images['pixel_values'],\n",
    "        'labels': labels\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': combined_train_dataset,\n",
    "    'validation': valid_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa3734f622f547499070902388dee9fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1238 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42d992dbb2864f70b26b520b82e5f0c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02bbd75671454d72af7ae710c6a7eb5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict['train'] = dataset_dict['train'].map(\n",
    "    lambda examples: preprocess_function(examples),\n",
    "    batched=True,\n",
    "    remove_columns=['image']\n",
    ")\n",
    "\n",
    "for split in ['validation', 'test']:\n",
    "    dataset_dict[split] = dataset_dict[split].map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        remove_columns=['image']\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfae0a8232ce4ab4896a899b51310b84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b947f7b955624025af087b515602b39e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a84f1e057e4725a1c70a3be4f98e1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5878a264734edebeda11ed395f6b17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbb37d4e1c849ee94e8180a851a449d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3022c44106e240ce8211f8e57d705d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71f7cd2df4f48a08c3e311128a78de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7137fc3284a461f8b7dc0437dbaa607",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21714c3c0ab8445db5bec48411f610a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87c85a6a42b4b14ba2ad29f451dff70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/247 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a8bda3a63424db898e60720f12d9df6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb157989e8ec4c1da4b19b5e8e90786c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2dff4d7ed554ea58c13ce3ca0ddd793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad5cef0b6f14bdfbb2e1d244c4a9060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45af49301c0646c9af55f7358122d4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1ea0d531f1f4d818bfe331b715f1a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1a9e6f051d244b6888abdca60badfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/e1010101/tongue-images-384-segmented-augmented/commit/2e78890e26c9b2688c0d089628d4accadf77f079', commit_message='Upload dataset', commit_description='', oid='2e78890e26c9b2688c0d089628d4accadf77f079', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.push_to_hub(\"e1010101/tongue-images-384-segmented-augmented\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
