{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"e1010101/tongue-images-384-segmented\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'labels', 'pixel_values'],\n",
       "        num_rows: 619\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'labels', 'pixel_values'],\n",
       "        num_rows: 181\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'labels', 'pixel_values'],\n",
       "        num_rows: 94\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataset(data_split, output_dir):\n",
    "    split_str = output_dir.split(\"_\")[-1]\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    images_dir = os.path.join(output_dir, \"images\")\n",
    "    os.makedirs(images_dir, exist_ok=True)\n",
    "    \n",
    "    metadata = []\n",
    "    for i, example in enumerate(tqdm(data_split, desc=f\"Saving {output_dir}\")):\n",
    "        image = example['image']\n",
    "        labels = example['labels']\n",
    "        image_filename = f\"{split_str}_image_{i:05d}.png\"\n",
    "        image.save(os.path.join(images_dir, image_filename))\n",
    "        metadata.append({\"filename\": image_filename, \"labels\": labels})\n",
    "    \n",
    "    with open(os.path.join(output_dir, \"metadata.csv\"), \"w\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=[\"filename\", \"labels\"])\n",
    "        writer.writeheader()\n",
    "        writer.writerows(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving downloaded_tongue_images_train: 100%|██████████| 619/619 [01:54<00:00,  5.38it/s]\n",
      "Saving downloaded_tongue_images_valid: 100%|██████████| 181/181 [00:34<00:00,  5.19it/s]\n",
      "Saving downloaded_tongue_images_test: 100%|██████████| 94/94 [00:50<00:00,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "save_dataset(dataset[\"train\"], \"downloaded_tongue_images_train\")\n",
    "save_dataset(dataset[\"validation\"], \"downloaded_tongue_images_valid\")\n",
    "save_dataset(dataset[\"test\"], \"downloaded_tongue_images_test\")\n",
    "\n",
    "print(\"Dataset saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
