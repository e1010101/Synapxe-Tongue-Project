{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "from datasets import Dataset, DatasetDict, Features, Image, Sequence, Value, concatenate_datasets\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import PIL\n",
    "import cv2\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08896053091644e19d0a594524d4794a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"dataset_segmented/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path + \"train/_classes.csv\")\n",
    "valid_df = pd.read_csv(data_path + \"valid/_classes.csv\")\n",
    "test_df = pd.read_csv(data_path + \"test/_classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>image_00000.png</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image_00001.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image_00002.png</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image_00003.png</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image_00004.png</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>image_00614.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>image_00615.png</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>image_00616.png</td>\n",
       "      <td>[1.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>image_00617.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>image_00618.png</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename           labels\n",
       "0    image_00000.png  [0.0, 0.0, 1.0]\n",
       "1    image_00001.png  [1.0, 1.0, 1.0]\n",
       "2    image_00002.png  [0.0, 1.0, 0.0]\n",
       "3    image_00003.png  [0.0, 1.0, 0.0]\n",
       "4    image_00004.png  [0.0, 1.0, 1.0]\n",
       "..               ...              ...\n",
       "614  image_00614.png  [1.0, 1.0, 1.0]\n",
       "615  image_00615.png  [1.0, 1.0, 0.0]\n",
       "616  image_00616.png  [1.0, 0.0, 1.0]\n",
       "617  image_00617.png  [1.0, 1.0, 1.0]\n",
       "618  image_00618.png  [0.0, 1.0, 1.0]\n",
       "\n",
       "[619 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_lab_features(image):\n",
    "    # Identify black pixels in the original image (RGB values are all zero)\n",
    "    black_mask = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) == 0\n",
    "    # Create an inverse mask for non-black pixels\n",
    "    non_black_mask = ~black_mask\n",
    "\n",
    "    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)\n",
    "    L_channel, A_channel, B_channel = cv2.split(lab_image)\n",
    "\n",
    "    # Apply the non-black mask to each channel\n",
    "    L_non_black = L_channel[non_black_mask]\n",
    "    A_non_black = A_channel[non_black_mask]\n",
    "    B_non_black = B_channel[non_black_mask]\n",
    "\n",
    "    if L_non_black.size == 0:\n",
    "        l_mean = 0\n",
    "        a_mean = 0\n",
    "        b_mean = 0\n",
    "    else:\n",
    "        l_mean = np.mean(L_non_black)\n",
    "        a_mean = np.mean(A_non_black)\n",
    "        b_mean = np.mean(B_non_black)\n",
    "\n",
    "    return l_mean, a_mean, b_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = ['train', 'valid', 'test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing images: 100%|██████████| 620/620 [00:13<00:00, 45.53it/s]\n",
      "c:\\Users\\ezrat\\anaconda3\\envs\\Project\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n",
      "Parsing images: 100%|██████████| 182/182 [00:03<00:00, 48.21it/s]\n",
      "c:\\Users\\ezrat\\anaconda3\\envs\\Project\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "Parsing images: 100%|██████████| 95/95 [00:01<00:00, 50.91it/s]\n",
      "c:\\Users\\ezrat\\anaconda3\\envs\\Project\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1429: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for split in splits:\n",
    "    base_image_path = f'dataset_segmented/{split}/'\n",
    "    images = os.listdir(base_image_path)\n",
    "    filenames = []\n",
    "    l_values = []\n",
    "    a_values = []\n",
    "    b_values = []\n",
    "\n",
    "    for image_file in tqdm(images, desc=\"Parsing images\"):\n",
    "        if image_file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            full_image_path = os.path.join(base_image_path, image_file)\n",
    "            image = cv2.imread(full_image_path)\n",
    "            if image is None:\n",
    "                print(f\"Error: Unable to read image at {full_image_path}\")\n",
    "                continue\n",
    "            \n",
    "            l_mean, a_mean, b_mean = extract_lab_features(image)\n",
    "            \n",
    "            filenames.append(full_image_path)\n",
    "            l_values.append(l_mean)\n",
    "            a_values.append(a_mean)\n",
    "            b_values.append(b_mean)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'image': filenames,\n",
    "        'L': l_values,\n",
    "        'A': a_values,\n",
    "        'B': b_values\n",
    "    })\n",
    "\n",
    "    X = df[['A', 'B']]\n",
    "    kmeans = KMeans(n_clusters=6, random_state=0)\n",
    "    kmeans.fit(X)\n",
    "    df['cluster'] = kmeans.labels_\n",
    "\n",
    "    # Save to .csv (optional)\n",
    "    df.to_csv(f'6_image_clusters_{split}.csv', index=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append image path to filename\n",
    "def add_image_path(df, split):\n",
    "    df['image'] = data_path + split + \"/\" + split + '_' + df['filename']\n",
    "    df = df[df['image'].apply(os.path.exists)]\n",
    "    return df[['image', 'labels']]\n",
    "\n",
    "train_dataset_df = add_image_path(train_df, \"train\")\n",
    "valid_dataset_df = add_image_path(valid_df, \"valid\")\n",
    "test_dataset_df = add_image_path(test_df, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset_segmented/train/train_image_00000.png</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset_segmented/train/train_image_00001.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset_segmented/train/train_image_00002.png</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset_segmented/train/train_image_00003.png</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset_segmented/train/train_image_00004.png</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>dataset_segmented/train/train_image_00614.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>dataset_segmented/train/train_image_00615.png</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>dataset_segmented/train/train_image_00616.png</td>\n",
       "      <td>[1.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>dataset_segmented/train/train_image_00617.png</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>dataset_segmented/train/train_image_00618.png</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image           labels\n",
       "0    dataset_segmented/train/train_image_00000.png  [0.0, 0.0, 1.0]\n",
       "1    dataset_segmented/train/train_image_00001.png  [1.0, 1.0, 1.0]\n",
       "2    dataset_segmented/train/train_image_00002.png  [0.0, 1.0, 0.0]\n",
       "3    dataset_segmented/train/train_image_00003.png  [0.0, 1.0, 0.0]\n",
       "4    dataset_segmented/train/train_image_00004.png  [0.0, 1.0, 1.0]\n",
       "..                                             ...              ...\n",
       "614  dataset_segmented/train/train_image_00614.png  [1.0, 1.0, 1.0]\n",
       "615  dataset_segmented/train/train_image_00615.png  [1.0, 1.0, 0.0]\n",
       "616  dataset_segmented/train/train_image_00616.png  [1.0, 0.0, 1.0]\n",
       "617  dataset_segmented/train/train_image_00617.png  [1.0, 1.0, 1.0]\n",
       "618  dataset_segmented/train/train_image_00618.png  [0.0, 1.0, 1.0]\n",
       "\n",
       "[619 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_clusters = pd.read_csv('6_image_clusters_train.csv')\n",
    "valid_clusters = pd.read_csv('6_image_clusters_valid.csv')\n",
    "test_clusters = pd.read_csv('6_image_clusters_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_train = train_dataset_df.merge(train_clusters, on='image')\n",
    "merged_df_valid = valid_dataset_df.merge(valid_clusters, on='image')\n",
    "merged_df_test = test_dataset_df.merge(test_clusters, on='image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "merged_df_train['labels'] = merged_df_train['labels'].apply(ast.literal_eval)\n",
    "merged_df_valid['labels'] = merged_df_valid['labels'].apply(ast.literal_eval)\n",
    "merged_df_test['labels'] = merged_df_test['labels'].apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_test.loc[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_train['labels'] = merged_df_train.apply(lambda row: row['labels'] + [float(row['cluster'])], axis=1)\n",
    "merged_df_valid['labels'] = merged_df_valid.apply(lambda row: row['labels'] + [float(row['cluster'])], axis=1)\n",
    "merged_df_test['labels'] = merged_df_test.apply(lambda row: row['labels'] + [float(row['cluster'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_train.drop(columns=['L', 'A', 'B', 'cluster'], inplace=True)\n",
    "merged_df_valid.drop(columns=['L', 'A', 'B', 'cluster'], inplace=True)\n",
    "merged_df_test.drop(columns=['L', 'A', 'B', 'cluster'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dataset_segmented/train/train_image_00000.png</td>\n",
       "      <td>[0.0, 0.0, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset_segmented/train/train_image_00001.png</td>\n",
       "      <td>[1.0, 1.0, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dataset_segmented/train/train_image_00002.png</td>\n",
       "      <td>[0.0, 1.0, 0.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dataset_segmented/train/train_image_00003.png</td>\n",
       "      <td>[0.0, 1.0, 0.0, 4.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dataset_segmented/train/train_image_00004.png</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>dataset_segmented/train/train_image_00614.png</td>\n",
       "      <td>[1.0, 1.0, 1.0, 3.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>dataset_segmented/train/train_image_00615.png</td>\n",
       "      <td>[1.0, 1.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>dataset_segmented/train/train_image_00616.png</td>\n",
       "      <td>[1.0, 0.0, 1.0, 2.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>dataset_segmented/train/train_image_00617.png</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>dataset_segmented/train/train_image_00618.png</td>\n",
       "      <td>[0.0, 1.0, 1.0, 5.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>619 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             image                labels\n",
       "0    dataset_segmented/train/train_image_00000.png  [0.0, 0.0, 1.0, 2.0]\n",
       "1    dataset_segmented/train/train_image_00001.png  [1.0, 1.0, 1.0, 2.0]\n",
       "2    dataset_segmented/train/train_image_00002.png  [0.0, 1.0, 0.0, 4.0]\n",
       "3    dataset_segmented/train/train_image_00003.png  [0.0, 1.0, 0.0, 4.0]\n",
       "4    dataset_segmented/train/train_image_00004.png  [0.0, 1.0, 1.0, 0.0]\n",
       "..                                             ...                   ...\n",
       "614  dataset_segmented/train/train_image_00614.png  [1.0, 1.0, 1.0, 3.0]\n",
       "615  dataset_segmented/train/train_image_00615.png  [1.0, 1.0, 0.0, 1.0]\n",
       "616  dataset_segmented/train/train_image_00616.png  [1.0, 0.0, 1.0, 2.0]\n",
       "617  dataset_segmented/train/train_image_00617.png  [1.0, 1.0, 1.0, 1.0]\n",
       "618  dataset_segmented/train/train_image_00618.png  [0.0, 1.0, 1.0, 5.0]\n",
       "\n",
       "[619 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 1.0, 2.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_train.loc[0]['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 4\n",
    "class_names = ['Crack', 'Red-Dots', 'Toothmark', 'Color']\n",
    "\n",
    "# Labels is an array of floats\n",
    "features = Features({\n",
    "    'image': Image(),\n",
    "    'labels': Sequence(feature=Value('float32'), length=num_classes)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(merged_df_train, features=features, preserve_index=False)\n",
    "valid_dataset = Dataset.from_pandas(merged_df_valid, features=features, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(merged_df_test, features=features, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DatasetDict({'train': train_dataset, 'validation': valid_dataset, 'test': test_dataset})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.PngImagePlugin.PngImageFile image mode=RGB size=640x640>,\n",
       " 'labels': [0.0, 0.0, 1.0, 2.0]}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
